{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"background-color:#F5F5F5;\" width=\"100%\">\n",
    "<tr><td style=\"background-color:#F5F5F5;\"><img src=\"../images/logo.png\" width=\"150\" align='right'/></td></tr>     <tr><td>\n",
    "            <h2><center>Aprendizagem Automática em Engenharia Biomédica</center></h2>\n",
    "            <h3><center>1st Semester - 2024/2025</center></h3>\n",
    "            <h4><center>Universidade Nova de Lisboa - Faculdade de Ciências e Tecnologia</center></h4>\n",
    "</td></tr>\n",
    "    <tr><td><h2><b><center>Lab 9 - Dimensionality Reduction</center></b></h2>\n",
    "    <h4><i><b><center>Human Activity Recognition Dataset</center></b></i></h4></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Curse of Dimensionality\n",
    "\n",
    "The Curse of Dimensionality is a known problem in modelling data for different objectives. It was coined by Richard Bellman in the 1950s and refers to the problems that arise when dealing with high-dimensional spaces.\n",
    "\n",
    "When we increase the number of dimensions of a problem, i.e. the number of features, the volume of the space becomes exponentially larger, thus making available samples sparser.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://drek4537l1klr.cloudfront.net/rhys/Figures/fig13-1_alt.jpg\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "As examples are represented in a larger space, it may become easier for the model to find a decision boundary that splits the data, thus leading to good performances. However, we rise the concern regarding overfitting.\n",
    "\n",
    "## 2. Feature Selection\n",
    "\n",
    "The feature extraction process improves the learning process by uncovering hidden and helpful relationships between data. However, it comes at the cost of increasing the complexity of the data and potentially leading to the Curse of Dimensionality problem.\n",
    "\n",
    "To avoid these problems while ensuring best performance, feature selection is a commonly applied process in Machine Learning pipelines where the best characteristics of the data, i.e. features, are identified. The most discriminative features are kept and used for the optimization process (with hyperparameter tuning).\n",
    "\n",
    "The feature selection process can be done resorting to multiple techniques, which usually fit into three main groups:\n",
    "\n",
    "* __Filter Methods__: These methods analyse the data structure and find independence among the feature set.\n",
    "\n",
    "* __Wrapper Methods__: Using a classifier, wrapper methods find the best features looking at the classification performance.\n",
    "\n",
    "* __Embedded Methods__: In embedded methods, the feature selection process is part of the learning process of the classifier.\n",
    "\n",
    "\n",
    "### 2.1. The UCI Human Activity Recognition Using Smartphones Data Set \n",
    "\n",
    "Let's recover the [UCI's Human Activity Recognition dataset](https://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions). In this class, the extracted features from TSFEL (Lab 5 and 6) are available in our GitHub page. Load the data directly from the links.\n",
    "\n",
    "##### 2.1.1. Loading the HAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv(\"https://raw.githubusercontent.com/hgamboa/nova-aaeb/main/Labs/Data/HAR/train_features.csv\")\n",
    "X_test = pd.read_csv(\"https://raw.githubusercontent.com/hgamboa/nova-aaeb/main/Labs/Data/HAR/test_features.csv\")\n",
    "y_train = np.loadtxt(\"https://raw.githubusercontent.com/hgamboa/nova-aaeb/main/Labs/Data/HAR/y_train.txt\")\n",
    "y_test = np.loadtxt(\"https://raw.githubusercontent.com/hgamboa/nova-aaeb/main/Labs/Data/HAR/y_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Exercice: Defining a Testing Classifier\n",
    "\n",
    "As we will test different methods for feature selection, it is important to guarantee a comparison methodology. Therefore, we should use the same classifier, under the same conditions, to evaluate the results.\n",
    "\n",
    "__Exercice 1__: Define a function using a tuned decision tree from previous experiments on the HAR dataset. The function should be designed to train the model, make predictions, and then display the performance results. Additionally, it should provide information about the number of features to help evaluate the model's complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_test_classifier(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Tuned decision tree\n",
    "    model = DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=100,\n",
    "                       max_leaf_nodes=30, min_samples_leaf=25,\n",
    "                       min_samples_split=50, random_state=42)\n",
    "    \n",
    "    # train model\n",
    "    \n",
    "    \n",
    "    # predictions\n",
    "    \n",
    "    \n",
    "    # performance results\n",
    "    \n",
    "    print(\"Performance:\")\n",
    "    print(\"\\tTrain Accuracy:\", )    \n",
    "    print(\"\\tTest  Accuracy:\", )\n",
    "    \n",
    "    print(\"Complexity:\")\n",
    "    print(\"\\tFeature Size:\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercice 2__: Verify the baseline performance, using the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Filter Methods\n",
    "\n",
    "Feature selection using Filter methods is the most simple way to select the most relevant features.\n",
    "\n",
    "In these methods, the data structure is analyzed in order to detect _independence_ among the several features. Several measurements are defined to extract information about the data structure:\n",
    "\n",
    "* __Correlation__\n",
    "\n",
    "* __Chi-Square__\n",
    "\n",
    "* __Information Gain__\n",
    "\n",
    "##### 2.3.1. Exploring Correlation\n",
    "\n",
    "Pandas library includes a method to automatically compute the correlation of a dataset. [`df.corr()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) computes the correlation matrix of the continuous variables of a dataset using the Pearson method. It is possible to explore other coefficients, such as the Spearman rank or the Kendall Tay correlation coefficients.\n",
    "\n",
    "Let's compute and evaluate the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pearson = X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def corr_heatmap(corr):\n",
    "    plt.figure(figsize=(16,14))\n",
    "    sns.heatmap(data=corr, cmap=plt.cm.Reds, vmin=-1, vmax=1)\n",
    "    \n",
    "corr_heatmap(corr_pearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2. Selecting Features\n",
    "\n",
    "To decide which features should be kept, one needs to identify highly correlated pairs and keep only one.\n",
    "\n",
    "We will define a method to identify the most correlated features using a reference threshold of 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def correlated_features(corr_matrix, threshold=0.95):\n",
    "    \n",
    "    # Absolute value\n",
    "    corr_matrix = corr_matrix.abs()\n",
    "    \n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Find index and column name of features with correlation greater than threshold\n",
    "    corr_features = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    \n",
    "    return corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = correlated_features(corr_pearson, threshold=0.95)\n",
    "\n",
    "print(\"No. correlated features:\", len(corr_features))\n",
    "corr_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Exercice\n",
    "\n",
    "__Exercice 3__: Now that we have identified the most correlated features, remove them from the datasets and verify the attained performance. What do you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Wrapper Methods\n",
    "\n",
    "With Wrapper, the best features are selected resorting to the evaluation of the classification performance of some model using different subsets of features. \n",
    "\n",
    "In Wrapper methods, the feature selection is done sequentially in an iterative process using two strategies:\n",
    "\n",
    "* __Forward Feature Selection__\n",
    "\n",
    "* __Backward Feature Selection__\n",
    "\n",
    "Sklearn includes the [SequentialFeatureSelector()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html) method, which allows to implement both strategies using a given estimator.\n",
    "\n",
    "##### 2.5.1. Forward Feature Selection\n",
    "\n",
    "The forward feature selection process sequentially adds new features to the train dataset until the maximum convergence is achieved.  \n",
    "\n",
    "The iterative testing and update runs as follows:\n",
    "\n",
    "1. Start with an empty feature set $Y_0 = [] $, an accuracy $a_0 = 0$, an objective function $J$ and an iteration counter$k = 0$;\n",
    "\n",
    "2. Select the feature $x^+$ that maximizes $J(Y_k + x)$;\n",
    "\n",
    "3. If $J(Y_k + x^+) > a_k$, update $Y_{k+1} = Y_k + x^+$, $a_{k+1} = J(Y_k + x^+)$ and $k=k+1$ and go back to 2., otherwise continue;\n",
    "\n",
    "4. Keep only the feature set $Y_k$ and discard the rest.\n",
    "\n",
    "### 2.6. Exercice\n",
    "\n",
    "__Exercice 4__: Using the `SequentialFeatureSelector()` method, implement a Forward Feature Selection strategy. Use the same estimator as the performance comparison method.\n",
    "\n",
    "Use cross validation with the train dataset after removing correlated features (X_train_corr), define a performance tolerance and set n_jobs equal to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercice 5__: Evaluate the performance with the new set of features. What do you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. Dimensionality Reduction - PCA\n",
    "\n",
    "Another way to reduce the number of features is by applying dimensionality reduction techniques, which aim to summarize the information content in large datasets by means of a smaller set of representative variables. The include aggregated information of multiple variables.\n",
    "\n",
    "__Principal Component Analysis (PCA)__ is the most well known dimensionality reduction technique. First it identifies the hyperplane that lies closest to the data, and then it projects the data onto it. The objective is to project data into their principal components by maximizing the variance of the training data.\n",
    "\n",
    "Sklearn includes an implentation of [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html).\n",
    "\n",
    "### 2.8. Exercice\n",
    "\n",
    "__Exercice 6__: Verify the impact of PCA in the train data after feature correlation. Use `mle` in n_components for the automatic estimation of the number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee3b8b0f13ce1b575702cf6f1b3dd3d8df18dc5f202e0bca1f4b2f664d388be6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
