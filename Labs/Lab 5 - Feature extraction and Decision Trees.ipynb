{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"background-color:#F5F5F5;\" width=\"100%\">\n",
    "<tr><td style=\"background-color:#F5F5F5;\"><img src=\"../images/logo.png\" width=\"100\" align='right'/></td></tr>     <tr><td>\n",
    "            <h1><center>Aprendizagem Automática em Engenharia Biomédica</center></h1>\n",
    "            <h3><center>1st Semester - 2021/2022</center></h3>\n",
    "            <h4><center>Universidade Nova de Lisboa - Faculdade de Ciências e Tecnologia</center></h4>\n",
    "</td></tr>\n",
    "    <tr><td><h1><center>Lab 5 - Feature Extraction and Decision Trees </center></h1></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inertial_data(acc_axis):\n",
    "    \n",
    "    # Load data from UCI\n",
    "    if not os.path.isfile('UCI HAR Dataset.zip'):\n",
    "        if platform == \"linux\" or platform == \"linux2\":\n",
    "            !wget http://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
    "        else:\n",
    "            !pip install wget\n",
    "            import wget\n",
    "            wget.download('http://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI HAR Dataset.zip')\n",
    "\n",
    "    # Unzip dataset\n",
    "    if not os.path.isdir('UCI HAR Dataset'):\n",
    "        zip_ref = zipfile.ZipFile(\"UCI HAR Dataset.zip\", 'r')\n",
    "        zip_ref.extractall()\n",
    "        zip_ref.close()\n",
    "    \n",
    "    # train data\n",
    "    X = np.loadtxt('UCI HAR Dataset/train/Inertial Signals/total_'+ acc_axis +'_train.txt')\n",
    "    X_train = np.hstack([wind[:64] for wind in X])\n",
    "\n",
    "    y_train = np.loadtxt('UCI HAR Dataset/train/y_train.txt', dtype=int)\n",
    "    y_train = np.repeat(y_train, 64)\n",
    "    \n",
    "    # test data\n",
    "    X = np.loadtxt('UCI HAR Dataset/test/Inertial Signals/total_'+ acc_axis +'_test.txt')\n",
    "    X_test = np.hstack([wind[:64] for wind in X])\n",
    "\n",
    "    y_test = np.loadtxt('UCI HAR Dataset/test/y_test.txt', dtype=int)\n",
    "    y_test = np.repeat(y_test, 64)\n",
    "    \n",
    "    # activity labels\n",
    "    activity_labels = pd.read_csv('UCI HAR Dataset/activity_labels.txt', index_col=0, header=None, sep=' ')\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, np.hstack(activity_labels.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1:__ Load data using the auxiliary function `get_intertial_data()` and use `acc_axis=\"acc_x\"` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_frequency = 50\n",
    "\n",
    "# train_data, train_labels, test_data, test_labels, activity_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ Plot accelerometer `x-axis` (train_data) and add vertical lines in the transitons of the activities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transitions = \n",
    "\n",
    "# Plot\n",
    "\n",
    "# plt.xlim(0,50000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ From the above plot we can see that there are significant differences in the amplitude of each activity. For a classification task we may want to provide a classification every `x` seconds. Using the previous signals we can calculate some features such as `np.mean()`, `np.max()` and `np.min` for every `5` seconds and evaluate if it enough to distinguish our classes.\n",
    "\n",
    "Divide the accelerometer `x-axis` into windows of `5 seconds` and then calculate the above features. \n",
    "Use `train_windows` variable to save the signal divided into windows and `X_train` variable for the feature vector.\n",
    "\n",
    "Expected sizes: `train_windows` - `[n_windows, window_size]` and `X_train` - `[n_windows, n_features]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define window size\n",
    "\n",
    "# define train_windows. Use an array as the final structure\n",
    "\n",
    "\n",
    "# calculate features  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of train windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the feature vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__ We divided our signal into windows, but we must know the class of each window. Go to the previous step and add a list of labels with the same size of our feature vector, assign it to `y_train`.\n",
    "\n",
    "If in the same window we have more than one class, what should we do? Define a strategy and justify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Now we have a feature vector composed by windows of `5` seconds. This means that if we train a model to classify our classes, we can predict a label every `5` seconds. But now imagine that we want to continue using `5 seconds` but with an update rate of `1 second`. \n",
    "\n",
    "Adapt the previous exercise to have an update rate of `1 second`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the size of feature vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look to the size of the feature vector of __Step 4__ and __Step 5__ you will see that increasing our update rate also increase the number of features. \n",
    "\n",
    "So, we have more data to train our model! But we must be careful with the spliting criteria of train and test set (remender this when perform data partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Make a histogram of each class to understand if we are working with a balanced dataset. Define the range and number of bins according to the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 7:__ Now, lets try to use our data to feed a simple Decision Tree. Define a function named `window_splitter` to split the signal into windows and a function named `feature_extraction` to calcule the 3 previous features. Use these functions to extract features from our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_splitter(data, labels, window_size, update_rate):\n",
    "    \n",
    "    \n",
    "    return windows, y\n",
    "\n",
    "def feature_extraction(windows):\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_windows, y_test = window_splitter(test_data, test_labels, window_size, update_rate)\n",
    "X_test = feature_extraction(test_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 8:__ Using [DecisionTreeClassifier()](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), create a `DecisionTreeClassifier` instance called `model`. Read the `DecisionTreeClassifier` parameters in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 9:__ Use the `.fit()` method to fit the model to the train feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 10:__ Use the `.predict()` method to predict the train and test data, assigning the result to `y_pred_train` and `y_pred_test` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = \n",
    "y_pred_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 11:__ Use the [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function to compare the train and test accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = \n",
    "acc_test = \n",
    "\n",
    "print('Train Accuracy: %.3f ' % acc_train)\n",
    "print('Test Accuracy : %.3f' % acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like that our model is __overfitted__ to the training data. Check the documentation of [DecisionTreeClassifier()](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) to understand which parameters you can change to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Avoiding Overfitting\n",
    "\n",
    "> Decision-tree learners can create over-complex trees that do not generalise the data well. This is called overfitting.\n",
    "    \n",
    "## Prepruning a tree\n",
    "\n",
    "The splitter <br>\n",
    "The maximum depth<br>\n",
    "The minimum number of samples required to split<br>\n",
    "The minimum samples in each leaf<br>\n",
    "The minimum weight fraction in each leaf<br>\n",
    "The maximum number of features]<br>\n",
    "The maximum number of leaf nodes<br>\n",
    "The minimum impurity decrease<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 12:__ Try to visualize your Decision Tree to see how complex it is. Install the following packages:\n",
    "\n",
    "`!pip install graphviz`\n",
    "\n",
    "`!pip install pydotplus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import pydotplus\n",
    "\n",
    "dot_data = export_graphviz(model, feature_names=[\"mean\", \"max\", \"min\"], class_names=activity_labels, \n",
    "                           filled=True)\n",
    "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "pydot_graph.set_size('\"20,20\"')\n",
    "graphviz.Source(pydot_graph.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 13:__ Now try to use a maximum depth of `5` and compare again the accuracy score and visualize the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "\n",
    "# Predict labels\n",
    "\n",
    "# Accuracy\n",
    "\n",
    "\n",
    "print('Train Accuracy: %.3f ' % acc_train)\n",
    "print('Test Accuracy : %.3f' % acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization. Use the same code of Step 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our Decision Tree is much more interpretable! Also the change of maximum depth resulted in an increase in our test accuracy. Try to change other parameters and see the results in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 14:__ Plot the confusion matrix to understand the misclassifications of our model. You can use the [plot_confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html) function ofsklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 15__: One way to improve our model performance is to extract more informative features that can help us in this discriminative task. For time-series we can extract several features from each window.\n",
    "\n",
    "Lets use a python library to extract more features.\n",
    "\n",
    "[TSFEL](https://tsfel.readthedocs.io/en/latest/) is a time series feature extractor library that extract features from the temporal, statistical and spectral domain. \n",
    "\n",
    "Install the library using `!pip install tsfel`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Feature extraction started ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>            \n",
       "              <progress\n",
       "                  value='8027'\n",
       "                  max='8027',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  8027\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Feature extraction finished ***\n",
      "*** Feature extraction started ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>            \n",
       "              <progress\n",
       "                  value='3178'\n",
       "                  max='3178',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  3178\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Feature extraction finished ***\n"
     ]
    }
   ],
   "source": [
    "import tsfel\n",
    "\n",
    "cfg = tsfel.get_features_by_domain()\n",
    "\n",
    "X_train = tsfel.time_series_features_extractor(cfg, train_windows, fs=sampling_frequency)\n",
    "X_test = tsfel.time_series_features_extractor(cfg, test_windows, fs=sampling_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 16__: Fit the model again with the new feature vector and calculate the accuracy score for both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "\n",
    "# Predict labels\n",
    "\n",
    "# Accuracy\n",
    "\n",
    "\n",
    "print('Train Accuracy: %.3f ' % acc_train)\n",
    "print('Test Accuracy : %.3f' % acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more features increased our accuracy! But now we have `250` features instead of `3`. \n",
    "\n",
    "With this high number of features we can apply feature selection methods (maybe increasing our accuracy again). In the next lab we will learn about feature selection methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 17:__ Save the train and test feature vector and the corresponding labels. You will need them in the next class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('UCI HAR Dataset/train_features.csv', index=False)\n",
    "X_test.to_csv('UCI HAR Dataset/test_features.csv', index=False)\n",
    "\n",
    "np.savetxt('UCI HAR Dataset/y_train.txt', y_train)\n",
    "np.savetxt('UCI HAR Dataset/y_test.txt', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
